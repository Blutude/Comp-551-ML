{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanNegativeDS1 = pd.read_csv(\"Datasets/DS1_m_0.txt\", header=None).drop([20], axis=1).as_matrix().flatten()\n",
    "meanPositiveDS1 = pd.read_csv(\"Datasets/DS1_m_1.txt\", header=None).drop([20], axis=1).as_matrix().flatten()\n",
    "covDS1 = pd.read_csv(\"Datasets/DS1_Cov.txt\", header=None).drop([20], axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNeg = np.random.multivariate_normal(meanNegativeDS1, covDS1, 2000)\n",
    "dataPos = np.random.multivariate_normal(meanPositiveDS1, covDS1, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNegLabelled = np.append(dataNeg, np.zeros((2000, 1)), axis=1)\n",
    "dataPosLabelled = np.append(dataPos, np.ones((2000, 1)), axis=1)\n",
    "\n",
    "np.random.shuffle(dataNegLabelled)\n",
    "np.random.shuffle(dataPosLabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = np.concatenate((dataNegLabelled[:1400], dataPosLabelled[:1400])) # 1400 = 70% of 2000\n",
    "dataTest = np.concatenate((dataNegLabelled[1400:], dataPosLabelled[1400:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dataTrain)\n",
    "np.random.shuffle(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "dataTestTrain = np.concatenate((dataTrain, dataTest))\n",
    "pd.DataFrame(data=dataTestTrain).to_csv(\"Datasets/DS1.csv\")\n",
    "pd.DataFrame(data=dataTest).to_csv(\"Datasets/DS1_test.csv\")\n",
    "pd.DataFrame(data=dataTrain).to_csv(\"Datasets/DS1_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitNegPos(dataTrain):\n",
    "    neg = []\n",
    "    pos = []\n",
    "    for row in dataTrain:\n",
    "        if (row[20] == 0):\n",
    "            neg.append(row)\n",
    "        elif (row[20] == 1):\n",
    "            pos.append(row)\n",
    "        else:\n",
    "            print \"problem here\"\n",
    "    return np.asmatrix(neg), np.asmatrix(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMeanVectors(neg, pos):\n",
    "    return np.mean(neg, axis=0).T, np.mean(pos, axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCovMatrix(neg, pos, negMean, posMean):\n",
    "    negS = np.zeros((20,20))\n",
    "    for row in neg:\n",
    "        m = np.subtract(row, negMean.T)\n",
    "        negS = negS + np.outer(m,m)\n",
    "    \n",
    "    posS = np.zeros((20,20))\n",
    "    for row in pos:\n",
    "        m = np.subtract(row, posMean.T)\n",
    "        posS = posS + np.outer(m,m)\n",
    "    \n",
    "    return np.divide(np.add(negS, posS), (len(neg)+len(pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2614427 ]\n",
      " [1.22836197]\n",
      " [1.20484808]\n",
      " [1.19626626]\n",
      " [1.23064767]\n",
      " [1.22655065]\n",
      " [1.22331304]\n",
      " [1.22607009]\n",
      " [1.21404533]\n",
      " [1.19369645]\n",
      " [1.28752386]\n",
      " [1.24790739]\n",
      " [1.21437172]\n",
      " [1.24192373]\n",
      " [1.20263893]\n",
      " [1.18126648]\n",
      " [1.22389339]\n",
      " [1.25489079]\n",
      " [1.27608961]\n",
      " [1.23021587]]\n",
      "[[2.02015181]\n",
      " [1.94693069]\n",
      " [2.05893388]\n",
      " [2.048659  ]\n",
      " [2.02830185]\n",
      " [2.0332283 ]\n",
      " [1.96369367]\n",
      " [1.98964359]\n",
      " [2.03352687]\n",
      " [1.98035308]\n",
      " [1.9902823 ]\n",
      " [2.00264695]\n",
      " [2.09793453]\n",
      " [1.97610669]\n",
      " [2.0142644 ]\n",
      " [1.99950455]\n",
      " [2.02826798]\n",
      " [1.96814903]\n",
      " [1.95431869]\n",
      " [2.124221  ]]\n"
     ]
    }
   ],
   "source": [
    "# Compututation for training\n",
    "neg, pos = splitNegPos(dataTrain)\n",
    "negMean, posMean = calcMeanVectors(neg[:, :-1], pos[:, :-1])\n",
    "print negMean\n",
    "print posMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = calcCovMatrix(neg[:, :-1], pos[:, :-1], negMean, posMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLDA(negMean, posMean, cov, priorProb):\n",
    "    w = np.dot(np.linalg.inv(cov), np.subtract(negMean, posMean))\n",
    "    w0 = np.divide(np.dot(np.dot(negMean.T, np.linalg.inv(cov)), negMean), -2) + np.divide(np.dot(np.dot(posMean.T, np.linalg.inv(cov)), posMean), 2) + np.log(priorProb/(1-priorProb))\n",
    "    return w, w0[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14.26748566]\n",
      " [ -8.56458378]\n",
      " [ -5.2998211 ]\n",
      " [ -2.805305  ]\n",
      " [ -9.61078056]\n",
      " [ -4.24652139]\n",
      " [ 16.28326505]\n",
      " [-23.82975939]\n",
      " [-28.57535375]\n",
      " [  9.27593724]\n",
      " [-12.75239082]\n",
      " [-11.79404412]\n",
      " [ 14.92196022]\n",
      " [ 12.39637746]\n",
      " [ -5.49517254]\n",
      " [ 12.78870123]\n",
      " [ 28.54886293]\n",
      " [ -6.36933361]\n",
      " [ -0.11832129]\n",
      " [ -5.08081374]]\n",
      "26.47968814971185\n"
     ]
    }
   ],
   "source": [
    "w, w0 = trainLDA(negMean, posMean, cov, 0.5) # Prior probability for negative class and positive class is 0.5\n",
    "print w\n",
    "print w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1/(1+np.exp(-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(dataTest, w, w0):\n",
    "    truePos, falsePos, falseNeg = 0, 0, 0\n",
    "    for row in dataTest:\n",
    "        label = row[-1]\n",
    "        row = row[:-1]\n",
    "        val = w0 + np.dot(w.T, row)\n",
    "        if (sigmoid(val) < 0.5):\n",
    "            if (label == 1):\n",
    "                truePos += 1\n",
    "            elif (label == 0):\n",
    "                falsePos += 1\n",
    "            else:\n",
    "                print \"problem here\"\n",
    "        else:\n",
    "            if (label == 1):\n",
    "                falseNeg += 1\n",
    "                \n",
    "    return truePos, falsePos, falseNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePos, falsePos, falseNeg = prediction(dataTest, w, w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "32\n",
      "31\n",
      "568\n",
      "Accuracy 0.9475\n",
      "Precision 0.946755407654\n",
      "Recall 0.948333333333\n",
      "fMeasure 0.947543713572\n"
     ]
    }
   ],
   "source": [
    "print truePos\n",
    "print falsePos\n",
    "print falseNeg\n",
    "print (len(dataTest)-falsePos-falseNeg-truePos) # trueNeg\n",
    "\n",
    "def evaluateConfusion(truePos, falsePos, falseNeg):\n",
    "    accuracy = (float(len(dataTest)-falsePos-falseNeg))/len(dataTest)\n",
    "    precision = float(truePos)/(truePos+falsePos)\n",
    "    recall = float(truePos)/(truePos+falseNeg)\n",
    "    fMeasure = 2*precision*recall/(precision+recall)\n",
    "    return accuracy, precision, recall, fMeasure\n",
    "\n",
    "accuracy, precision, recall, fMeasure = evaluateConfusion(truePos, falsePos, falseNeg)\n",
    "\n",
    "print \"Accuracy \" + str(accuracy)\n",
    "print \"Precision \" + str(precision)\n",
    "print \"Recall \" + str(recall)\n",
    "print \"fMeasure \" + str(fMeasure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(k, dataTrain, index, distances):\n",
    "    indices = np.argpartition(distances[index], k)[:k]\n",
    "    closestLabel = [dataTrain[i, -1] for i in indices]\n",
    "    return np.argmax(np.bincount(closestLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(k, dataTest, dataTrain, distances):\n",
    "    return [kNN(k, dataTrain, i, distances) for i in range(len(dataTest))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusion(predictedLabels, trueLabels):\n",
    "    truePos, falsePos, falseNeg = 0, 0, 0\n",
    "    for i in range(len(predictedLabels)):\n",
    "        if predictedLabels[i] == 1:\n",
    "            if (trueLabels[i] == 1):\n",
    "                truePos += 1\n",
    "            else:\n",
    "                falsePos += 1\n",
    "        else:\n",
    "            if (trueLabels[i] == 1):\n",
    "                falseNeg += 1\n",
    "                \n",
    "    return truePos, falsePos, falseNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestK(dataTest, dataTrain, distances):\n",
    "    f1 = []\n",
    "    for k in range(1, 100):\n",
    "        predictedLabels = getPredictions(k, dataTest, dataTrain, distances)\n",
    "        tp, fp, fn = getConfusion(predictedLabels, dataTest[:, -1])\n",
    "        a, p, r, f = evaluateConfusion(tp, fp, fn)\n",
    "        f1.append(f)\n",
    "    return np.argmax(f1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [[np.linalg.norm(np.subtract(x, row)) for row in dataTrain[:, :-1]] for x in dataTest[:, :-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "bestK = findBestK(dataTest, dataTrain, distances)\n",
    "print bestK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "267\n",
      "221\n",
      "333\n",
      "Accuracy 0.593333333333\n",
      "Precision 0.586687306502\n",
      "Recall 0.631666666667\n",
      "fMeasure 0.60834670947\n"
     ]
    }
   ],
   "source": [
    "predictedLabels = getPredictions(bestK, dataTest, dataTrain, distances)\n",
    "truePos, falsePos, falseNeg = getConfusion(predictedLabels, dataTest[:, -1])\n",
    "\n",
    "print truePos\n",
    "print falsePos\n",
    "print falseNeg\n",
    "print (len(dataTest)-falsePos-falseNeg-truePos) # trueNeg\n",
    "\n",
    "accuracy, precision, recall, fMeasure = evaluateConfusion(truePos, falsePos, falseNeg)\n",
    "\n",
    "print \"Accuracy \" + str(accuracy)\n",
    "print \"Precision \" + str(precision)\n",
    "print \"Recall \" + str(recall)\n",
    "print \"fMeasure \" + str(fMeasure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1PosDS2 = pd.read_csv('Datasets/DS2_c1_m1.txt', header = None).drop([20], axis=1).as_matrix().flatten()\n",
    "mean2PosDS2 = pd.read_csv('Datasets/DS2_c1_m2.txt', header = None).drop([20], axis=1).as_matrix().flatten()\n",
    "mean3PosDS2 = pd.read_csv('Datasets/DS2_c1_m3.txt', header = None).drop([20], axis=1).as_matrix().flatten()\n",
    "\n",
    "mean1NegDS2 = pd.read_csv('Datasets/DS2_c2_m1.txt', header = None).drop([20], axis=1).as_matrix().flatten()\n",
    "mean2NegDS2 = pd.read_csv('Datasets/DS2_c2_m2.txt', header = None).drop([20], axis=1).as_matrix().flatten()\n",
    "mean3NegDS2 = pd.read_csv('Datasets/DS2_c2_m3.txt', header = None).drop([20], axis=1).as_matrix().flatten()\n",
    "\n",
    "cov1 = pd.read_csv(\"Datasets/DS2_Cov1.txt\", header=None).drop([20], axis=1).as_matrix()\n",
    "cov2 = pd.read_csv(\"Datasets/DS2_Cov2.txt\", header=None).drop([20], axis=1).as_matrix()\n",
    "cov3 = pd.read_csv(\"Datasets/DS2_Cov3.txt\", header=None).drop([20], axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNeg1 = pd.DataFrame(data = np.random.multivariate_normal(mean1NegDS2, cov1, 2000)).sample(frac=0.1)\n",
    "dataNeg2 = pd.DataFrame(data = np.random.multivariate_normal(mean2NegDS2, cov2, 2000)).sample(frac=0.42)\n",
    "dataNeg3 = pd.DataFrame(data = np.random.multivariate_normal(mean3NegDS2, cov3, 2000)).sample(frac=0.48)\n",
    "\n",
    "dataNeg = np.concatenate((np.concatenate((np.array(dataNeg1), np.array(dataNeg2))), np.array(dataNeg3)))\n",
    "\n",
    "dataPos1 = pd.DataFrame(data = np.random.multivariate_normal(mean1PosDS2, cov1, 2000)).sample(frac=0.1)\n",
    "dataPos2 = pd.DataFrame(data = np.random.multivariate_normal(mean2PosDS2, cov2, 2000)).sample(frac=0.42)\n",
    "dataPos3 = pd.DataFrame(data = np.random.multivariate_normal(mean3PosDS2, cov3, 2000)).sample(frac=0.48)\n",
    "\n",
    "dataPos = np.concatenate((np.concatenate((np.array(dataPos1), np.array(dataPos2))), np.array(dataPos3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNeg = np.append(dataNeg,np.zeros((2000,1)), axis=1)\n",
    "dataPos = np.append(dataPos,np.ones((2000,1)), axis=1)\n",
    "\n",
    "np.random.shuffle(dataNeg)\n",
    "np.random.shuffle(dataPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = np.concatenate((dataNeg[:1400], dataPos[:1400])) # 1400 = 70% of 2000\n",
    "dataTest = np.concatenate((dataNeg[1400:], dataPos[1400:]))\n",
    "\n",
    "np.random.shuffle(dataTrain)\n",
    "np.random.shuffle(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "dataTestTrain = np.concatenate((dataTrain, dataTest))\n",
    "pd.DataFrame(data=dataTestTrain).to_csv(\"Datasets/DS2.csv\")\n",
    "pd.DataFrame(data=dataTest).to_csv(\"Datasets/DS2_test.csv\")\n",
    "pd.DataFrame(data=dataTrain).to_csv(\"Datasets/DS2_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.23159085]\n",
      " [1.21440199]\n",
      " [1.22689487]\n",
      " [1.25150563]\n",
      " [1.22008269]\n",
      " [1.20869373]\n",
      " [1.23334347]\n",
      " [1.22760068]\n",
      " [1.23644895]\n",
      " [1.14081003]\n",
      " [1.21692361]\n",
      " [1.26056693]\n",
      " [1.15851963]\n",
      " [1.20855883]\n",
      " [1.20449102]\n",
      " [1.21191718]\n",
      " [1.22553093]\n",
      " [1.2748046 ]\n",
      " [1.20158003]\n",
      " [1.28470286]]\n",
      "[[0.90399085]\n",
      " [0.92570532]\n",
      " [0.90304828]\n",
      " [0.90641961]\n",
      " [0.93223767]\n",
      " [0.94906293]\n",
      " [0.95772628]\n",
      " [0.90850007]\n",
      " [0.96578773]\n",
      " [0.89749443]\n",
      " [0.89876744]\n",
      " [0.88778945]\n",
      " [0.94711165]\n",
      " [0.92193447]\n",
      " [0.95454802]\n",
      " [0.87710736]\n",
      " [0.84973135]\n",
      " [0.93040217]\n",
      " [0.87877994]\n",
      " [0.96662294]]\n"
     ]
    }
   ],
   "source": [
    "# Compututation for training\n",
    "neg, pos = splitNegPos(dataTrain)\n",
    "negMean, posMean = calcMeanVectors(neg[:, :-1], pos[:, :-1])\n",
    "print negMean\n",
    "print posMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = calcCovMatrix(neg[:, :-1], pos[:, :-1], negMean, posMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00946916]\n",
      " [-0.01071975]\n",
      " [ 0.00348337]\n",
      " [ 0.04809125]\n",
      " [ 0.04067397]\n",
      " [-0.01343135]\n",
      " [-0.07591526]\n",
      " [-0.0011989 ]\n",
      " [ 0.0334194 ]\n",
      " [-0.0148552 ]\n",
      " [ 0.03488377]\n",
      " [ 0.03138586]\n",
      " [-0.05492472]\n",
      " [ 0.00450722]\n",
      " [-0.04654164]\n",
      " [ 0.02846735]\n",
      " [ 0.05301648]\n",
      " [ 0.0214602 ]\n",
      " [ 0.02288127]\n",
      " [-0.01627267]]\n",
      "-0.08174814948270964\n"
     ]
    }
   ],
   "source": [
    "w, w0 = trainLDA(negMean, posMean, cov, 0.5) # Prior probability for negative class and positive class is 0.5\n",
    "print w\n",
    "print w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePos, falsePos, falseNeg = prediction(dataTest, w, w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n",
      "287\n",
      "296\n",
      "313\n",
      "Accuracy 0.514166666667\n",
      "Precision 0.514382402707\n",
      "Recall 0.506666666667\n",
      "fMeasure 0.510495382032\n"
     ]
    }
   ],
   "source": [
    "print truePos\n",
    "print falsePos\n",
    "print falseNeg\n",
    "print (len(dataTest)-falsePos-falseNeg-truePos) # trueNeg\n",
    "\n",
    "accuracy, precision, recall, fMeasure = evaluateConfusion(truePos, falsePos, falseNeg)\n",
    "\n",
    "print \"Accuracy \" + str(accuracy)\n",
    "print \"Precision \" + str(precision)\n",
    "print \"Recall \" + str(recall)\n",
    "print \"fMeasure \" + str(fMeasure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [[np.linalg.norm(np.subtract(x, row)) for row in dataTrain[:, :-1]] for x in dataTest[:, :-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "bestK = findBestK(dataTest, dataTrain, distances)\n",
    "print bestK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n",
      "287\n",
      "274\n",
      "313\n",
      "Accuracy 0.5325\n",
      "Precision 0.531810766721\n",
      "Recall 0.543333333333\n",
      "fMeasure 0.537510305029\n"
     ]
    }
   ],
   "source": [
    "predictedLabels = getPredictions(bestK, dataTest, dataTrain, distances)\n",
    "truePos, falsePos, falseNeg = getConfusion(predictedLabels, dataTest[:, -1])\n",
    "\n",
    "print truePos\n",
    "print falsePos\n",
    "print falseNeg\n",
    "print (len(dataTest)-falsePos-falseNeg-truePos) # trueNeg\n",
    "\n",
    "accuracy, precision, recall, fMeasure = evaluateConfusion(truePos, falsePos, falseNeg)\n",
    "\n",
    "print \"Accuracy \" + str(accuracy)\n",
    "print \"Precision \" + str(precision)\n",
    "print \"Recall \" + str(recall)\n",
    "print \"fMeasure \" + str(fMeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
