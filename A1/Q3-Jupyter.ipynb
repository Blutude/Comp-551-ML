{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileName = \"Datasets/Dataset_3.csv\"\n",
    "\n",
    "def cleanup():\n",
    "    data = pd.read_csv(fileName, header=None)\n",
    "    # Remove first 5 columns as they are non-predictive\n",
    "    data = data.drop(range(5), axis=1)\n",
    "    \n",
    "    naColIndex = [col for col in data.columns[data.isnull().any()]] # list of column indexes with missing values\n",
    "    # Filling missing values with random values between (mean-std, mean+std) because simply filling it with the mean would have too many similar values and would create skew\n",
    "    for col in naColIndex:\n",
    "        mean = data[col].mean()\n",
    "        std = data[col].std()\n",
    "        if (mean-std < 0):\n",
    "            randomList = np.random.uniform(0, mean+std, size=data[col].isnull().sum()) # values are all positive\n",
    "        else:\n",
    "            randomList = np.random.uniform(mean-std, mean+std, size=data[col].isnull().sum())\n",
    "\n",
    "        data[col][np.isnan(data[col])] = randomList\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = cleanup()\n",
    "data.to_csv(\"Datasets/Dataset_3_complete.csv\") # Turning in complete data set\n",
    "\n",
    "def addOnes(data):\n",
    "    data.insert(0,'',1)\n",
    "    data.column = [np.arange(0, data.shape[1])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using functions from Q2 and slightly modifying them\n",
    "\n",
    "def predictedY(row, weights):\n",
    "    return sum([row[i]*w for i,w in enumerate(weights)])\n",
    "\n",
    "def updateWeights(row, y, w, a): # a is learning rate\n",
    "    pred_y = predictedY(row, w)\n",
    "    w = [wi - a*(pred_y-y)*row[i] for i,wi in enumerate(w)]\n",
    "    return w\n",
    "\n",
    "def epoch(x, y, w, a):\n",
    "    for i in range(len(x)):\n",
    "        w = updateWeights(x[i], y[i], w, a)\n",
    "    \n",
    "    return w\n",
    "\n",
    "def calcMse(pred_y, y):\n",
    "    error = 0\n",
    "    for i in range(len(y)):\n",
    "        error += (pred_y[i] - y[i])**2\n",
    "        \n",
    "    error /= len(y)\n",
    "    return error\n",
    "\n",
    "def runEpochs(x, y, epochsNb, stepSize):\n",
    "    converged = False\n",
    "    convergenceRate = 1e-5\n",
    "    mses = []\n",
    "    w = [1 for i in range(len(x[0]))]\n",
    "    itr = 0\n",
    "    while(not converged and itr < epochsNb): # sweeps\n",
    "        w = epoch(x, y, w, stepSize)\n",
    "        pred_y = [predictedY(x[i], w) for i in range(len(y))]\n",
    "        mses.append(calcMse(pred_y, y))\n",
    "        if (itr>1 and abs(mses[-1]-mses[-2])<convergenceRate):\n",
    "            converged = True\n",
    "        itr = itr+1\n",
    "    return w, mses, itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffleData(randomSeed):\n",
    "    data = cleanup()\n",
    "    data = addOnes(data)\n",
    "    train = data.sample(frac=0.8, random_state=randomSeed)\n",
    "    test = data.drop(train.index)\n",
    "    \n",
    "    train = train.reset_index()\n",
    "    test = test.reset_index()\n",
    "    \n",
    "    return [train, test]\n",
    "\n",
    "sets = []\n",
    "sets.append(shuffleData(100))\n",
    "sets.append(shuffleData(125))\n",
    "sets.append(shuffleData(150))\n",
    "sets.append(shuffleData(175))\n",
    "sets.append(shuffleData(200))\n",
    "for i in range(sets):\n",
    "    sets[i][0].to_csv(\"Datasets/Dataset_3_train_split\"+str(i)+\".csv\")\n",
    "    sets[i][1].to_csv(\"Datasets/Dataset_3_test_split\"+str(i)+\".csv\")\n",
    "\n",
    "testMsesAndWeights = []\n",
    "for i in range(len(sets)):\n",
    "    x = [row[:-1] for row in sets[i][0].as_matrix()] # list of rows\n",
    "    y = [row[-1] for row in sets[i][0].as_matrix()] # list of output\n",
    "    w, mses, epochsRan = runEpochs(x, y, 5000, 1e-3)\n",
    "    print(epochsRan, mses[-1])\n",
    "    \n",
    "    pred_y = [predictedY(x[i], w) for i in range(len(y))]\n",
    "    test_y = [row[-1] for row in sets[i][1].as_matrix()]\n",
    "    testMse = calcMse(pred_y, test_y)\n",
    "    testMsesAndWeights.append([testMse, w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for testMseAndW in testMsesAndWeights:\n",
    "    print(testMseAndW[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
